{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf2_intro.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ML-Guy/DummyGenerartorData/blob/master/tf2_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yV8PnLPnkSxw",
        "colab_type": "text"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mj0y8haUmEbG",
        "colab_type": "code",
        "outputId": "4e1a5d3d-5b93-4b98-fb1d-5cbbbc7df2cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        }
      },
      "source": [
        "!pip install tensorflow==2.0.0-alpha0\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0.0-alpha0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/39/f99185d39131b8333afcfe1dcdb0629c2ffc4ecfb0e4c14ca210d620e56c/tensorflow-2.0.0a0-cp36-cp36m-manylinux1_x86_64.whl (79.9MB)\n",
            "\u001b[K     |████████████████████████████████| 79.9MB 61.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (0.33.4)\n",
            "Collecting google-pasta>=0.1.2 (from tensorflow==2.0.0-alpha0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/68/a14620bfb042691f532dcde8576ff82ee82e4c003cdc0a3dbee5f289cee6/google_pasta-0.1.6-py3-none-any.whl (51kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 22.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (3.7.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (0.8.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.12.0)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 (from tensorflow==2.0.0-alpha0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/82/f16063b4eed210dc2ab057930ac1da4fbe1e91b7b051a6c8370b401e6ae7/tf_estimator_nightly-1.14.0.dev2019030115-py2.py3-none-any.whl (411kB)\n",
            "\u001b[K     |████████████████████████████████| 419kB 42.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.15.0)\n",
            "Collecting tb-nightly<1.14.0a20190302,>=1.14.0a20190301 (from tensorflow==2.0.0-alpha0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/51/aa1d756644bf4624c03844115e4ac4058eff77acd786b26315f051a4b195/tb_nightly-1.14.0a20190301-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 33.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.0.9)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.0.7)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.16.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (0.7.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (0.2.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0-alpha0) (41.0.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha0) (0.15.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha0) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-alpha0) (2.8.0)\n",
            "Installing collected packages: google-pasta, tf-estimator-nightly, tb-nightly, tensorflow\n",
            "  Found existing installation: tensorflow 1.13.1\n",
            "    Uninstalling tensorflow-1.13.1:\n",
            "      Successfully uninstalled tensorflow-1.13.1\n",
            "Successfully installed google-pasta-0.1.6 tb-nightly-1.14.0a20190301 tensorflow-2.0.0a0 tf-estimator-nightly-1.14.0.dev2019030115\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoE4uoz5kYMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "dataset = tfds.load('fashion_mnist',as_supervised=True)\n",
        "ds_train, ds_test = dataset['train'],dataset['test']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7FIl9tisTu2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist_train = tfds.load(name=\"mnist\", split=tfds.Split.TRAIN)\n",
        "# tfds.load is really a thin conveninence wrapper around DatasetBuilder. \n",
        "# We can accomplish the same as above directly with the MNIST DatasetBuilder\n",
        "mnist_builder = tfds.builder(\"mnist\")\n",
        "mnist_builder.download_and_prepare()\n",
        "mnist_train = mnist_builder.as_dataset(split=tfds.Split.TRAIN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA33FqWk1hEs",
        "colab_type": "text"
      },
      "source": [
        "All DatasetBuilders expose various data subsets defined as tfds.Splits (typically tfds.Split.TRAIN and tfds.Split.TEST). A given dataset's splits are defined in tfds.DatasetBuilder.info.splits and are accessible through tfds.load and tfds.DatasetBuilder.as_dataset, both of which take split= as a keyword argument.\n",
        "\n",
        "tfds enables you to further manipulate splits by combining them or subsplitting them up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGAb-cHa1zp0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combined_split = tfds.Split.TRAIN + tfds.Split.TEST\n",
        "ds = tfds.load(\"mnist\", split=combined_split)\n",
        "# Ds will iterate over all splits merged together\n",
        "ds = tfds.load(\"mnist\", split=tfds.Split.ALL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYJk1Nc12cEN",
        "colab_type": "text"
      },
      "source": [
        "## Subsplit\n",
        "You have 3 options for how to get a thinner slice of the data than the base splits, all based on tfds.Split.subsplit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuaYBpFD2g7x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_half_1, train_half_2 = tfds.Split.TRAIN.subsplit(2) #\n",
        "first_10_percent = tfds.Split.TRAIN.subsplit(tfds.percent[:10])\n",
        "last_2_percent = tfds.Split.TRAIN.subsplit(tfds.percent[-2:])\n",
        "middle_50_percent = tfds.Split.TRAIN.subsplit(tfds.percent[25:75])\n",
        "half, quarter1, quarter2 = tfds.Split.TRAIN.subsplit([2, 1, 1])\n",
        "# composition : Split the combined TRAIN and TEST splits into 2\n",
        "first_half, second_half = (tfds.Split.TRAIN + tfds.Split.TEST).subsplit(2)\n",
        "\n",
        "#Invalid Operations: a split cannot be added twice, and subsplitting can only happen once.\n",
        "split = tfds.Split.TRAIN.subsplit(tfds.percent[:25]) + tfds.Split.TRAIN     # TRAIN included twice\n",
        "split = (tfds.Split.TRAIN.subsplit(tfds.percent[:25]) + tfds.Split.TEST).subsplit(tfds.percent[0:50])   # Subsplit of subsplit\n",
        "\n",
        "dataset = tfds.load(\"mnist\", split=train_half_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sg-WHImuo72G",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "List of datasets : https://www.tensorflow.org/datasets/datasets\n",
        "\n",
        "image_label_folder : Generic image classification dataset created from manual directory.\n",
        "  Reference : https://github.com/tensorflow/datasets/blob/master/tensorflow_datasets/image/image_folder.py\n",
        "  \n",
        "  The data directory should have the following structure:\n",
        "  ```\n",
        "  path/to/manual_dir/<dataset_name>/\n",
        "    split_name/  # Ex: 'train'\n",
        "      label1/  # Ex: 'airplane' or '0015'\n",
        "        xxx.png\n",
        "        xxy.png\n",
        "        xxz.png\n",
        "      label2/\n",
        "        xxx.png\n",
        "        xxy.png\n",
        "        xxz.png\n",
        "    split_name/  # Ex: 'test'\n",
        "      ...\n",
        "  ```\n",
        "  To use it:\n",
        "  ```\n",
        "  builder = tfds.image.ImageLabelFolder('<dataset_name>')\n",
        "  dl_config = tfds.download.DownloadConfig(manual_dir='path/to/manual_dir/')\n",
        "  builder.download_and_prepare(download_config=dl_config)\n",
        "  print(builder.info)  # Splits, num examples,... automatically extracted\n",
        "  ds = builder.as_dataset(split='split_name')\n",
        "  ```\n",
        "  Or with load:\n",
        "  ```\n",
        "  dl_config = tfds.download.DownloadConfig(manual_dir='path/to/manual_dir/')\n",
        "  tfds.load(\n",
        "      'image_label_folder',\n",
        "      split='split_name'\n",
        "      builder_kwargs=dict(dataset_name='<dataset_name>'),\n",
        "      download_and_prepare_kwargs=dict(download_config=dl_config),\n",
        "  )\n",
        "  ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKC74nn2C3LV",
        "colab_type": "text"
      },
      "source": [
        "![DatasetBuilder abstraction layers](https://www.tensorflow.org/datasets/dataset_layers.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmXa1mB6p6Pf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create custom dataset\n",
        "class DatasetBuilder:\n",
        "  # Source data -> Preprocessed files\n",
        "  def download_and_prepare:\n",
        "    \n",
        "  # Preprocessed files -> tf.data.Dataset \n",
        "  def as_dataset:\n",
        "    \n",
        "  # Dataset metadata: features, stats, etc.\n",
        "  def info:"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Vr9wUIpMiUU",
        "colab_type": "text"
      },
      "source": [
        "https://www.youtube.com/watch?v=oFFbKogYdfc&t=349s\n",
        "\n",
        "Example: https://github.com/tensorflow/datasets/blob/master/tensorflow_datasets/image/celeba.py\n",
        "\n",
        "Info is good. Three step process is also good. still complex to build new dataset. \n",
        "Feature column, tf.transform and tf.data.Datasets all are have overlapping functionlities/methods to reuse pipeline b/w train and inference runs. Beam pipeline based methods would have been great.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-i9tDprlYNZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ds = create_dataset()\n",
        "\n",
        "def scale(image,label):\n",
        "  image = tf.cast(image,tf.float32)\n",
        "  image /= 255\n",
        "  return image,label\n",
        "\n",
        "ds_train = ds_train.map(preprocess,num_parallel_calls=10).map(scale)\n",
        "ds_train = ds_train.shuffle(1024).batch(64).repeat(10).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "ds_test = ds_test.map(scale).batch(64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvGhI7c8kk6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqoPef4gVve-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=MyModel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc1d_6ikb-31",
        "colab_type": "text"
      },
      "source": [
        "Keras's way :Simple and succient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WTN5sElbV-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optmizer='adam',\n",
        "             loss='sparse_categorical_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "model.fit(xtrain,ytrain,epoch=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdLoI70UcJwi",
        "colab_type": "text"
      },
      "source": [
        "With Gradient Tape: More customisable \n",
        "con: increase in tech debt - more difficult to understand other's code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSwz6t8uaDZu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.GradientTape() as tape:\n",
        "  logits = model(images)\n",
        "  loss_value = loss(logits,labels)\n",
        "  \n",
        "grads = tape.gradient(loss_value,model.trainable_variables)\n",
        "optimizer.apply_gradients(zip(grads,model.trainable_variables))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mj6xNm9cpbH",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OodfWQ6fco_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def f(x):\n",
        "  return x\n",
        "\n",
        "print(tf.autograph.to_code(f)) #To see how tf.function changes py func to graph.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QJcziFgBEa6",
        "colab_type": "text"
      },
      "source": [
        "# Pending List\n",
        "\n",
        "- https://www.tensorflow.org/model_optimization \n",
        "- Tf probability \n",
        "- https://www.tensorflow.org/lite/guide/get_started#2_convert_the_model_format \n",
        "- TF Data Validation,  TF transform, TF Modal Analysis, TF serving, WhatIf, Tensorboard, hub \n",
        "- [ Good practice python guide (google)](https://github.com/google/styleguide/blob/gh-pages/pyguide.md) and [PEP 8 style guide](https://www.python.org/dev/peps/pep-0008/)\n",
        "- [Apache Beam Programming Guide](https://beam.apache.org/documentation/programming-guide/)\n",
        "- "
      ]
    }
  ]
}